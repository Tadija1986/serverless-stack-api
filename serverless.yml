# contains the configuration on what AWS services Serverless will provision and how to configure them
# NOTE: update this with your service name, 
# Serverless Framework creates your stack on AWS using this as the name
service: notes-app-2-api

# Create an optimized package for our functions
# Serverless Framework to create a single package per Lambda function 
package:
  individually: true

plugins:
  - serverless-bundle # Package our functions with Webpack
  - serverless-offline # helpful for local development
  - serverless-dotenv-plugin # Load .env as environment variables

custom:
  # Our stage is based on what is passed in when running serverless
  # commands. Or fallsback to what we have set in the provider section for stage.
  stage: ${opt:stage, self:provider.stage}
  # Set the table name here so we can use it while testing locally in development it is dev-notes, at production it is prod-notes
  tableName: ${self:custom.stage}-notes

provider:
  name: aws
  runtime: nodejs12.x
  stage: dev
  region: us-east-1
  # These environment variables are made available to our functions
  # under process.env.
  # The name of DynamoDB table from the environment variable can be used as variable process.env.tableName
  environment:
    # self:custom.tableName
    tableName: ${self:custom.tableName}
    # The STRIPE_SECRET_KEY from the .env file down gets loaded as an environment variable when we test our code locally
    # This allows us to add a Lambda environment variable called stripeSecretKey
    # We do this using the stripeSecretKey: ${env:STRIPE_SECRET_KEY} line
    # And just like our tableName environment variable, we can reference it in our Lambda function using process.env.stripeSecretKey
    stripeSecretKey: ${env:STRIPE_SECRET_KEY}
  # To load environment variables externally
  # rename env.example to .env and uncomment
  # the following line. Also, make sure to not
  # commit your .env.
  #
  #environment:
  #  SAMPLE_ENV_VAR: ${env:SAMPLE_ENV_VAR}

  # 'iamRoleStatements' defines the permission policy (which resources have access to) for the Lambda function.
  # In this case Lambda functions are granted with permissions to access DynamoDB.
  iamRoleStatements:
    - Effect: Allow
      Action:
        - dynamodb:DescribeTable
        - dynamodb:Query
        - dynamodb:Scan
        - dynamodb:GetItem
        - dynamodb:PutItem
        - dynamodb:UpdateItem
        - dynamodb:DeleteItem
      # Restrict our IAM role permissions to
      # the specific table for the stage
      Resource:
        - "Fn::GetAtt": [ NotesTable, Arn ]
      # Resource: "arn:aws:dynamodb:us-east-1:*:*"
      # Specifying DynamoDB using, roughly pointing to every DynamoDB table in the us-east-1 region

# Configure the API Endpoints
# This pattern of using a single Lambda function to respond to a single HTTP event is very much like the Microservices architecture
 # Defines an HTTP API endpoint that calls the main function in create.js
  # - path: url path is /notes
  # - method: POST request
  # - cors: enabled CORS (Cross-Origin Resource Sharing) for browser cross
  #     domain api call, our frontend is going to be served from a different domain
  # - authorizer: authenticate using the AWS IAM role
functions:
  create:
    handler: create.main
    events:
      - http:
          path: notes
          method: post
          cors: true
          authorizer: aws_iam

  get:
    # Defines an HTTP API endpoint that calls the main function in get.js
    # - path: url path is /notes/{id}
    # - method: GET request
    handler: get.main
    memorySize: 128
    timeout: 20
    events:
      - http:
          path: notes/{id}
          method: get
          cors: true
          authorizer: aws_iam
  list:
  # Defines an HTTP API endpoint that calls the main function in list.js
  # - path: url path is /notes
  # - method: GET request
  # - cors: enabled CORS (Cross-Origin Resource Sharing) for browser cross
  #     domain api call, our frontend is going to be served from a different domain
  # - authorizer: authenticate using the AWS IAM role
    handler: list.main
    events:
      - http:
          path: notes
          method: get
          cors: true
          authorizer: aws_iam
  update:
  # Defines an HTTP API endpoint that calls the main function in update.js
  # - path: url path is /notes/{id}
  # - method: PUT request
  # - cors: enabled CORS (Cross-Origin Resource Sharing) for browser cross
  #     domain api call, our frontend is going to be served from a different domain
  # - authorizer: authenticate using the AWS IAM role
    handler: update.main
    events:
      - http:
          path: notes/{id}
          method: put
          cors: true
          authorizer: aws_iam
  delete:
  # Defines an HTTP API endpoint that calls the main function in delete.js
  # - path: url path is /notes/{id}
  # - method: DELETE request
  # - cors: enabled CORS (Cross-Origin Resource Sharing) for browser cross
  #     domain api call, our frontend is going to be served from a different domain
  # - authorizer: authenticate using the AWS IAM role
    handler: delete.main
    events:
      - http:
          path: notes/{id}
          method: delete
          cors: true
          authorizer: aws_iam
  billing:
  # Defines an HTTP API endpoint that calls the main function in billing.js
  # - path: url path is /billing
  # - method: POST request
    handler: billing.main
    events:
      - http:
          path: billing
          method: post
          cors: true
          authorizer: aws_iam

# Create our resources with separate CloudFormation templates
resources:
  # API Gateway Errors
  - ${file(resources/api-gateway-errors.yml)}
  # DynamoDB
  - ${file(resources/dynamodb-table.yml)}
  # S3
  - ${file(resources/s3-bucket.yml)}
  # Cognito
  - ${file(resources/cognito-user-pool.yml)}
  - ${file(resources/cognito-identity-pool.yml)}


# serverless.yml is the easiest way to compose Serverless Components into an application
# using component with Serverless Framework
# A serverless website hosted on AWS S3, delivered globally and quickly w/ AWS Cloudfront, via a custom domain on AWS Route 53, secured by a free AWS ACM SSL Certificate:
# name: website

# website: # An instance of a component is declared here.
  #component: '@serverless/website' # This is the component you want to create an instance of. This is the NPM package name and can also use version name ex. @3.0.5.
  # inputs: # These are inputs to pass into the component's "default()" function
    # code:  
      # src: dist
      # hook: npm run build
    # domain: www.tntapplication.com

# Welcome to Serverless!
#
# This file is the main config file for your service.
# It's very minimal at this point and uses default values.
# You can always add more config options for more control.
# We've included some commented out config examples here.
# Just uncomment any of them to get that config option.
#
# For full config options, check the docs:
#    docs.serverless.com
#
# Happy Coding!

# service: hello
# app and org for use with dashboard.serverless.com
# app: hello
# org: nikolatadic

# You can pin your service to only deploy with a specific Serverless version
# Check out our docs for more details
# frameworkVersion: "=X.X.X"

# provider:
#   name: aws
#   runtime: nodejs12.x

# you can overwrite defaults here
#  stage: dev
#  region: us-east-1

# you can add statements to the Lambda function's IAM Role here
#  iamRoleStatements:
#    - Effect: "Allow"
#      Action:
#        - "s3:ListBucket"
#      Resource: { "Fn::Join" : ["", ["arn:aws:s3:::", { "Ref" : "ServerlessDeploymentBucket" } ] ]  }
#    - Effect: "Allow"
#      Action:
#        - "s3:PutObject"
#      Resource:
#        Fn::Join:
#          - ""
#          - - "arn:aws:s3:::"
#            - "Ref" : "ServerlessDeploymentBucket"
#            - "/*"

# you can define service wide environment variables here
#  environment:
#    variable1: value1

# you can add packaging information here
#package:
#  include:
#    - include-me.js
#    - include-me-dir/**
#  exclude:
#    - exclude-me.js
#    - exclude-me-dir/**

# functions:
#   hello:
#     handler: handler.hello
#     events:
#       - http: 
#           path: /hello
#           method: get
#    The following are a few example events you can configure
#    NOTE: Please make sure to change your handler code to work with those events
#    Check the event documentation for details
#    events:
#      - http:
#          path: users/create
#          method: get
#      - websocket: $connect
#      - s3: ${env:BUCKET}
#      - schedule: rate(10 minutes)
#      - sns: greeter-topic
#      - stream: arn:aws:dynamodb:region:XXXXXX:table/foo/stream/1970-01-01T00:00:00.000
#      - alexaSkill: amzn1.ask.skill.xx-xx-xx-xx
#      - alexaSmartHome: amzn1.ask.skill.xx-xx-xx-xx
#      - iot:
#          sql: "SELECT * FROM 'some_topic'"
#      - cloudwatchEvent:
#          event:
#            source:
#              - "aws.ec2"
#            detail-type:
#              - "EC2 Instance State-change Notification"
#            detail:
#              state:
#                - pending
#      - cloudwatchLog: '/aws/lambda/hello'
#      - cognitoUserPool:
#          pool: MyUserPool
#          trigger: PreSignUp
#      - alb:
#          listenerArn: arn:aws:elasticloadbalancing:us-east-1:XXXXXX:listener/app/my-load-balancer/50dc6c495c0c9188/
#          priority: 1
#          conditions:
#            host: example.com
#            path: /hello

#    Define function environment variables here
#    environment:
#      variable2: value2

# you can add CloudFormation resource templates here
#resources:
#  Resources:
#    NewResource:
#      Type: AWS::S3::Bucket
#      Properties:
#        BucketName: my-new-bucket
#  Outputs:
#     NewOutput:
#       Description: "Description for the output"
#       Value: "Some output value"
